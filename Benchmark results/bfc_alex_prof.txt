Parsing Inputs...

=========================Options=============================
-max_depth                  20
-min_bytes                  1
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 1
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              0
-min_occurrence             0
-step                       -1
-order_by                   accelerator_micros
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     bytes,micros
-output                     stdout:

==================Model Analysis Report======================

Doc:
op: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.
requested bytes: The memory requested by the operation, accumulatively.
total execution time: Sum of accelerator execution time and cpu execution time.
cpu execution time: The time from the start to the end of the operation. It's the sum of actual cpu run time plus the time that it spends waiting if part of computation is launched asynchronously.
accelerator execution time: Time spent executing on the accelerator. This is normally measured by the actual hardware library.

Profile:
node name | requested bytes | total execution time | accelerator execution time | cpu execution time
MatMul                        238.63MB (100.00%, 6.48%),     239.39ms (100.00%, 26.56%),     238.96ms (100.00%, 30.79%),         427us (100.00%, 0.34%)
Conv2DBackpropFilter          868.08MB (93.52%, 23.56%),      239.64ms (73.44%, 26.59%),      151.42ms (69.21%, 19.51%),       88.22ms (99.66%, 70.48%)
Conv2D                       1171.37MB (69.96%, 31.80%),      130.32ms (46.85%, 14.46%),      126.79ms (49.70%, 16.34%),         3.53ms (29.18%, 2.82%)
Conv2DBackpropInput           929.74MB (38.16%, 25.24%),      114.86ms (32.40%, 12.74%),       90.43ms (33.37%, 11.65%),       24.42ms (26.35%, 19.51%)
ApplyGradientDescent                  0B (0.00%, 0.00%),        47.18ms (19.65%, 5.23%),        44.34ms (21.71%, 5.71%),          2.84ms (6.84%, 2.27%)
AddN                                  0B (0.00%, 0.00%),        47.36ms (14.42%, 5.25%),        43.96ms (16.00%, 5.66%),          3.39ms (4.57%, 2.71%)
Mul                            248.42MB (12.93%, 6.74%),         23.10ms (9.16%, 2.56%),        22.72ms (10.34%, 2.93%),           364us (1.86%, 0.29%)
MaxPoolGrad                      48.23MB (6.18%, 1.31%),         16.47ms (6.60%, 1.83%),         16.35ms (7.41%, 2.11%),           119us (1.57%, 0.10%)
BiasAdd                               0B (0.00%, 0.00%),          8.42ms (4.77%, 0.93%),          8.27ms (5.30%, 1.07%),           143us (1.47%, 0.11%)
L2Loss                           14.34KB (4.87%, 0.00%),          7.61ms (3.84%, 0.84%),          7.08ms (4.24%, 0.91%),           517us (1.36%, 0.41%)
ReluGrad                              0B (0.00%, 0.00%),          6.31ms (3.00%, 0.70%),          6.18ms (3.32%, 0.80%),           115us (0.95%, 0.09%)
Relu                                  0B (0.00%, 0.00%),          5.97ms (2.30%, 0.66%),          5.88ms (2.53%, 0.76%),            91us (0.85%, 0.07%)
MaxPool                          11.30MB (4.87%, 0.31%),          5.43ms (1.63%, 0.60%),          5.34ms (1.77%, 0.69%),            90us (0.78%, 0.07%)
Transpose                        19.79MB (4.57%, 0.54%),          4.51ms (1.03%, 0.50%),          4.48ms (1.08%, 0.58%),            28us (0.71%, 0.02%)
BiasAddGrad                     145.90MB (4.03%, 3.96%),          3.40ms (0.53%, 0.38%),          2.90ms (0.50%, 0.37%),           496us (0.69%, 0.40%)
SparseSoftmaxCrossEntropyWithLogits           768B (0.07%, 0.00%),           513us (0.15%, 0.06%),           438us (0.13%, 0.06%),            74us (0.29%, 0.06%)
RealDiv                           1.47MB (0.07%, 0.04%),           393us (0.10%, 0.04%),           304us (0.07%, 0.04%),            86us (0.23%, 0.07%)
Add                                   0B (0.00%, 0.00%),           156us (0.05%, 0.02%),           107us (0.04%, 0.01%),            48us (0.16%, 0.04%)
RandomUniform                     1.05MB (0.03%, 0.03%),           130us (0.04%, 0.01%),            86us (0.02%, 0.01%),            42us (0.13%, 0.03%)
Floor                                 0B (0.00%, 0.00%),            99us (0.02%, 0.01%),            70us (0.01%, 0.01%),            29us (0.09%, 0.02%)
RandomUniformInt                    256B (0.00%, 0.00%),            97us (0.01%, 0.01%),            10us (0.00%, 0.00%),            86us (0.07%, 0.07%)

======================End of Report==========================
TensorFlow:  1.11
Model:       alexnet
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  32 global
             32.0 per device
Num batches: 100
Num epochs:  0.00
Devices:     ['/gpu:0']
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
Generating model
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 31.7 +/- 0.0 (jitter = 0.0)	7.357
10	images/sec: 39.3 +/- 0.8 (jitter = 0.1)	7.357
20	images/sec: 40.2 +/- 0.4 (jitter = 0.5)	7.357
30	images/sec: 40.5 +/- 0.3 (jitter = 0.2)	7.357
40	images/sec: 40.6 +/- 0.2 (jitter = 0.3)	7.357
50	images/sec: 40.7 +/- 0.2 (jitter = 0.2)	7.357
60	images/sec: 40.7 +/- 0.2 (jitter = 0.2)	7.357
70	images/sec: 40.7 +/- 0.1 (jitter = 0.2)	7.357
80	images/sec: 40.8 +/- 0.1 (jitter = 0.2)	7.357
90	images/sec: 40.8 +/- 0.1 (jitter = 0.2)	7.357
100	images/sec: 40.8 +/- 0.1 (jitter = 0.1)	7.357
----------------------------------------------------------------
total images/sec: 39.39
----------------------------------------------------------------
Dumping ProfileProto to bfc_alex.prof
