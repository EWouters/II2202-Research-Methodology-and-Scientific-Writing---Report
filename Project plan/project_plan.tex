%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% template for II2202 report
%% original 2015.11.24
%% revised  2018.08.26
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%

\title{GPU Dynamic memory allocation algorithms for Machine Learning: A survey}
\author{
        \textsc{Erik H. Wouters}
            \qquad
        \textsc{Dragos S. Perju}
        \mbox{}\\
        \normalsize
            \texttt{ehwo}
        \textbar{}
            \texttt{dsperju}
        \normalsize
            \texttt{@kth.se}
}
\date{\today}

\documentclass[12pt,twoside]{article}

\usepackage[paper=a4paper,dvips,top=1.5cm,left=1.5cm,right=1.5cm,
    foot=1cm,bottom=1.5cm]{geometry}
    
\usepackage[numbers]{natbib}
\bibliographystyle{IEEEtranN}


\usepackage{todonotes}
\usepackage{enumitem}
\usepackage{pgfgantt}

\usepackage[QX,T1]{fontenc}
%%\usepackage{pslatex}
\renewcommand{\rmdefault}{ptm} 
\usepackage{mathptmx}
\usepackage[scaled=.90]{helvet}
\usepackage{courier}
\usepackage{bookmark}

\usepackage{fancyhdr}
\pagestyle{fancy}

%%----------------------------------------------------------------------------
%%   pcap2tex stuff
%%----------------------------------------------------------------------------
 \usepackage[dvipsnames*,svgnames]{xcolor} %% For extended colors
 \usepackage{tikz}
 \usetikzlibrary{arrows,decorations.pathmorphing,backgrounds,fit,positioning,calc,shapes}

%% \usepackage{pgfmath}	% --math engine
%%----------------------------------------------------------------------------
%% \usepackage[latin1]{inputenc}
\usepackage[utf8]{inputenc} % inputenc allows the user to input accented characters directly from the keyboard
\usepackage[swedish,english]{babel}

%% \usepackage{rotating}		 %% For text rotating
\usepackage{array}			 %% For table wrapping
\usepackage{graphicx}	                 %% Support for images
\usepackage{float}			 %% Support for more flexible floating box positioning
\usepackage{color}                       %% Support for colour 
\usepackage{mdwlist}
%% \usepackage{setspace}                 %% For fine-grained control over line spacing
%% \usepackage{listings}		 %% For source code listing
%% \usepackage{bytefield}                %% For packet drawings
\usepackage{tabularx}		         %% For simple table stretching
%%\usepackage{multirow}	                 %% Support for multirow colums in tables
\usepackage{dcolumn}	                 %% Support for decimal point alignment in tables
\usepackage{url}	                 %% Support for breaking URLs
\usepackage[perpage,para,symbol]{footmisc} %% use symbols to ``number'' footnotes and reset which symbol is used first on each page

%% \usepackage{pygmentize}           %% required to use minted -- see python-pygments - Pygments is a Syntax Highlighting Package written in Python
%% \usepackage{minted}		     %% For source code highlighting

%% \usepackage{hyperref}		
\usepackage[all]{hypcap}	 %% Prevents an issue related to hyperref and caption linking
%% setup hyperref to use the darkblue color on links
%% \hypersetup{colorlinks,breaklinks,
%%             linkcolor=darkblue,urlcolor=darkblue,
%%             anchorcolor=darkblue,citecolor=darkblue}

%% Some definitions of used colors
\definecolor{darkblue}{rgb}{0.0,0.0,0.3} %% define a color called darkblue
\definecolor{darkred}{rgb}{0.4,0.0,0.0}
\definecolor{red}{rgb}{0.7,0.0,0.0}
\definecolor{lightgrey}{rgb}{0.8,0.8,0.8} 
\definecolor{grey}{rgb}{0.6,0.6,0.6}
\definecolor{darkgrey}{rgb}{0.4,0.4,0.4}
%% Reduce hyphenation as much as possible
\hyphenpenalty=15000 
\tolerance=1000

%% useful redefinitions to use with tables
\newcommand{\rr}{\raggedright} %% raggedright command redefinition
\newcommand{\rl}{\raggedleft} %% raggedleft command redefinition
\newcommand{\tn}{\tabularnewline} %% tabularnewline command redefinition

%% definition of new command for bytefield package
\newcommand{\colorbitbox}[3]{%
	\rlap{\bitbox{#2}{\color{#1}\rule{\width}{\height}}}%
	\bitbox{#2}{#3}}

%% command to ease switching to red color text
\newcommand{\red}{\color{red}}
%%redefinition of paragraph command to insert a breakline after it
\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
  {-3.25ex\@plus -1ex \@minus -.2ex}%
  {1.5ex \@plus .2ex}%
  {\normalfont\normalsize\bfseries}}
\makeatother

%%redefinition of subparagraph command to insert a breakline after it
\makeatletter
\renewcommand\subparagraph{\@startsection{subparagraph}{5}{\z@}%
  {-3.25ex\@plus -1ex \@minus -.2ex}%
  {1.5ex \@plus .2ex}%
  {\normalfont\normalsize\bfseries}}
\makeatother

\setcounter{tocdepth}{3}	%% 3 depth levels in TOC
\setcounter{secnumdepth}{5}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% End of preamble
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewcommand{\headrulewidth}{0pt}
\lhead{II2202, Fall 2018, Period 1-2}
%% or \lhead{II2202, Fall 2016, Period 1}
\chead{Project Plan}
\rhead{\date{\today}}

\makeatletter
\let\ps@plain\ps@fancy 
\makeatother

\setlength{\headheight}{15pt}
\begin{document}

\maketitle


%\begin{abstract}
%\label{sec:abstract}
%
%Your abstract here.
%
%\end{abstract}
%%\clearpage

\selectlanguage{english}

%\section*{List of Acronyms and Abbreviations}
%\label{list-of-acronyms-and-abbreviations}

%\todo{Place title here – use Arial 16 points and bold}
%\todo{The length of this project plan shall not be longer than 3-5 pages (with about 400 words – 600 words describing the project) excluding title, authors, milestone chart, and appendix. Save the document in a file with a name of the form: "author1\_author2-Task\_1-Project\_Plan-YYYYMMDD" For the text - use Georgia, 12 points, 1 1/2 line spacing. Note: All sections must be descriptive and most will contain more than one sentence!}

%This document requires readers to be familiar with terms and concepts described in \mbox{RFC~1235} \cite{john_ioannidis_coherent_1991}. For clarity we summarize some of these terms and give a short description of them before presenting them in next sections.

%\begin{basedescript}{\desclabelstyle{\pushlabel}\desclabelwidth{10em}}
%\item[IPv4]					Internet Protocol version 4 (RFC~791 \cite{postel_internet_1981})
%\item[IPv6]					Internet Protocol version 6 (RFC~2460 \cite{deering_internet_1998})
%\end{basedescript}


%\clearpage

\section{Allocation of responsibilities}
\label{sec:allocation-of-responsibilities}

%\todo{List authors and allocation of responsibilities. Answer the question: Who will be involved and what are their responsibilities within the project? For example:}

Erik Wouters is responsible of adapting the benchmark source code of \cite{Vinkler2015} to work with TensorFlow \cite{abadi2016}, afterwards running it on his own platform, with his specific GPU (which will be the base platform for the conducted research), and obtain the results for analysis.

Dragoş Perju is responsible for analyzing the results, choosing the base factors for comparison of the selected algorithms for study and finally providing a conclusive discussion of the findings. He is also responsible for presenting the ethics and sustainability aspect of the conducted research. He will assist in adapting the benchmark code of \cite{Vinkler2015} to work with TensorFlow.

Both authors will share the workload for writing the report, as well as presenting the final project.

\section{Organization}
\label{sec:organization}

%\todo{One or more sentences. This describes how the project is to be organized. For example:}

The project will be organized as a two-person project, building upon previously published work and tools. The work and benchmark of \citeauthor{Vinkler2015} \cite{Vinkler2015} will be integrated with the open source Machine Learning framework TensorFlow \cite{abadi2016}. The previously mentioned benchmark and software need to be integrated in order to create the complete testbed, after which data collection and analysis is able to proceed in parallel.

\section{Background}
\label{sec:background}

%\todo{Describe the background for chosen area that is going to be investigated. Write a short description of the area that is going to be investigated. It is a brief description of the necessary background knowledge of the problem area and for carrying out the project. For example:}

Previous work by \citeauthor{Vinkler2015} \cite{Vinkler2015} compares different GPU dynamic memory allocation algorithms under several workloads, many being generic well-known allocation patterns. \citeauthor{Vinkler2015}, however, propose one extra workload -- the \textit{building of k-d tree data structures} -- to test the algorithms under real-world conditions. Such data structures are used for ray tracing, to produce lighting and shadows when rendering 3D images \cite{Wald_Havran_2006} \cite{Rademacher_1997}.

GPUs have long been used for generating 3D images, such as for games or movies. Along with the appearance of CUDA and OpenGL, GPUs were able to be exploited for their full processing power and new, innovative programming techniques came to light. Machine Learning is one example of the latter, gaining much traction as a field of study and a basis for applications today. As such, we propose to conduct a research comparing different GPU dynamic memory allocation algorithms, tested under the workload of a well-known tool used for Machine Learning: TensorFlow, developed by Google Brain Team \cite{abadi2016}.

\section{Theoretical framework}
\label{sec:theoretical-framework}

Dynamic memory allocation is a technique well-known and often used by programmers. Much of the work for improvement and research has been devoted in the context of single-core and multi-core CPUs \cite{YOU2015}. In comparison to static memory allocation, which happens at program compilation time, dynamic memory allocation brings along issues with its use, such as fragmentation and memory leakage \cite{TRAISTER199099}.

Fragmentation is the cause of many memory allocation errors: as a program runs it finds itself in a situation where, although there is enough free memory to request the allocation of a big contiguous block, it is not possible due to the free memory being spread among uncoalesced smaller allocated blocks of memory that occupy much of the heap. Memory leakage happens when an allocated memory loses all references to it (e.g.: pointers) before it is deallocated, occupying the heap memory until the program is restarted.

Such problems along with others make dynamic memory allocation algorithms improper for use on specific platforms, such as safety-critical embedded systems \cite{Puaut_2002}. The technique however did progress to be implemented on other systems than generic CPUs, such as GPUs. GPUs introduce new difficulties in implementing dynamic memory allocation, being many-core systems running many more threads than a usual CPU. GPUs however evolved to be used for more than just rendering images, being used for programming techniques such as Machine Learning. This makes dynamic memory allocation on GPUs important in the context of today's world.

%Different programming languages offer different ways of managing variables. Most of them use a dynamic memory allocation algorithm. This algorithm returns a memory address when request to create a new variable is executed. In higher level programming languages there is no direct interaction with the memory addresses, but in lower level languages programmers can employ advanced techniques to manage the memory more efficiently for a specific application \cite{TRAISTER199099}.

\section{Problem Statement}
\label{sec:problem-statement}

%\todo{Describe the problem(s) that have been found in the area described in the background. Describe the problem area (in detail). For example:}

% \textbf{\textit{Maybe this book can be cited somewhere:}} \cite{GINSBURG2017345} \\

CUDA offers, to programmers who want to take advantage of GPU's processing power, a proprietary, unpublished algorithm for dynamically allocating memory called \texttt{CudaMalloc}. However, dynamic memory allocation algorithms running on the CPU are often customized for certain programs that require the edge in speed or stability, such as video games, database engines and so on. It is only natural to suspect that Machine Learning algorithms would be able to deliver faster performances if an allocator tailored for their needs would be selected as well.

We believe that \texttt{CudaMalloc}, as a general purpose dynamic memory allocation algorithm for the GPU, can be replaced for better performances when using the TensorFlow \cite{abadi2016} library for Machine Learning processing. In particular the ResNet-50 implementation of TensorFlow will be evaluated, which is a Convolutional Neural Network (CNN) with many layers and will therefore allocate many small sized objects in the GPU memory \cite{DBLP:HeZRS15}.
Algorithms that possibly perform better are mentioned in the work of \citeauthor{Vinkler2015} \cite{Vinkler2015}. They state that \texttt{CudaMalloc} is slower to process than other allocation algorithms for allocating many small sized objects, as shown in Figure 3a in \cite{Vinkler2015}. We decide to therefore select the better allocation algorithm for the task at hand, through the proposed research.

\section{Problem}
\label{sec:problem}

%\todo{State a clear and concise problem that is going to be investigated.  Answer the question What is the real problem? - What is the problem or value proposition addressed by the project? – Ideally one sentence that is very concrete. For example:}

%Fast Machine Learning processing imposes specific constraints of the dynamic memory allocator that runs on the GPU, 

The memory allocation pattern of TensorFlow's implementation of ResNet-50 is not a great match for the memory allocator TensorFlow uses, we will investigate which previously published dynamic memory allocation algorithms perform better.

%The need for fast Machine Learning processing, by improving the dynamic memory allocation that runs on the GPU.

%Select the fastest, state of the art, open source GPU dynamic memory allocation algorithm for a Machine Learning workload.

\section{Hypothesis}
\label{sec:hypothesis}

%\todo{State a hypothesis that you think would be the outcome of your investigation. Answer the question: What is your hypothesis? (Note that the hypothesis must be measurable to be confirmed or falsified. Moreover not all projects have hypothesis.).}

Our hypothesis is that one or more of the algorithms described by \citeauthor{Vinkler2015} \cite{Vinkler2015} perform better as a memory allocator for TensorFlow's implementation of ResNet-50 than the stock \texttt{BFCAllocator} or the standard \texttt{CudaMalloc} does, in terms of overall speed, fragmentation and stability.

%when allocation requests vary in size or frequency (consecutive or varied requests).

\section{Purpose}
\label{sec:purpose}

%\todo{Explain the purpose(s) of your project / investigation (the expected deliverables from the project). Answer the question: Why do this project? (purpose/effect, i.e. – the purpose can be to save environment but the goal is to build a robot that can pick up trash.) Why would you carry out the project? For example:}

Machine Learning is a technology that helps with the advancement on many problems we are struggling with today. From drug discovery \cite{Ramsundar_Kearnes_Riley_Webster_Konerding_Pande_2015} to sorting cucumbers by quality \cite{cucumber}, Machine Learning has applications in domains such as medical, agricultural, security, marketing and many others. It is through the presented project that we want to contribute to the progress of a programming tool that betters the lives of people.

\section{Goal(s)}
\label{sec:goal(s)}

%\todo{Explain the goal(s), objective(s), and/or the result(s) of your investigation. What are the expected deliverables/outcomes from the project? For example:}

1. Design a repeatable experiment that shows that one of the GPU memory allocation algorithms presented by \citeauthor{Vinkler2015} \cite{Vinkler2015} is faster than the standard \texttt{CudaMalloc} function. This experiment will be used to validate the hypothesis. 2. Understand why this algorithm is faster (or slower).
If we find a faster algorithm, send results and recommendation to the TensorFlow team for study and possible implementation in the release version.

\section{Tasks}
\label{sec:tasks}

%\todo{Describe the tasks and sub tasks that are necessary to complete the work. Grouped into a work breakdown structure. For example:}

Get the evaluation platform ready for the experiment and document the particular setup.
Write scripts for the setup to ensure repeatibility and consistancy between runs.
Use the NVIDIA Visual Profiler on the TensorFlow benchmarks to obtain the memory access pattern and distill the characteristics from this pattern.
Compile TensorFlow and run TensorFlow benchmarks using the standard \texttt{CudaMalloc}.
Repeat previous step, replacing the memory allocation algorithm with one described by \citeauthor{Vinkler2015} \cite{Vinkler2015}, for a subset of the algorithms in their paper.
Analyze the results of the benchmarks.

\section{Methods}
\label{sec:methods}

%\todo{Describe and explain the research methods that will be used for the project. What research method (or methods) will be used? Argue: why this is the most appropriate method or methods. For example:}

We will compile TensorFlow on Erik Wouters' HP ZBook workstation laptop (equipped with an NVIDIA K1100M GPU) and run the TensorFlow Convolutional Neural Network benchmarks from \url{https://github.com/tensorflow/benchmarks}. To compare the different memory algorithms, we will repeat the compilation and benchmarking with a subset of the memory allocation algorithms described by \citeauthor{Vinkler2015} \cite{Vinkler2015}.

The project will use the empirical method \cite{bock2001}. As we are evaluating using a well known benchmark from the Machine Learning field, this will provide results that mimic real world performance of these algorithms applied to Machine Learning \cite{abadi2016}. In order to create results that are as repeatable as possible, each test will be run 5 times and then the times will be averaged together. The NVIDIA K1100M GPU will run in it's default state on Erik Wouters' HP ZBook. For each test, 10 warm-up steps will be done and then the next 100 steps will be averaged.

\section{Results and Analysis}
\label{sec:results-and-analysis}
Initial tests have shown that profiling GPU accelerated sessions in TensorFlow takes a lot of compute time. Compiling TensorFlow takes about two hours on the workstation that is used for benchmarking. The full benchmark as it is run on the website of TensorFlow cannot be run on the NVIDIA K1100M GPU, as it will run out of memory. Decreasing the batch size from 32 to 16 fixes this problem.

The ResNet-50 benchmark in its standard form (with batch size 16) takes about 5.5 minutes to run. The full benchmark runs 110 iterations including the warm-up. To run only a single iteration using the NVIDIA Visual Profiler takes 17 hours. It is therefore not feasible to run the full benchmark (with 110 iterations) with the Visual Profiler. However profiling a single iteration provides enough insight in the memory allocation pattern for further analysis.

\section{Milestone chart (time schedule)}
\label{sec:milestone-chart}

%\todo{Give a detailed schedule of how the project will be carried out. What is the project timeline and when will particularly meaningful points, referred to as milestones, be completed? What is the deliverable for each of these milestones? For example:}

\begin{enumerate}[leftmargin=2cm]
    \item[Sep 19] Finish the project plan
    \item[Sep 21] Presentation of Ethics \& Sustainability of the proposed research
    \item[Sep 24] Study the algorithms described by \citeauthor{Vinkler2015} \cite{Vinkler2015}, select the most applicable ones for the Machine Learning workload and run the benchmark code on them
    \item[Oct 01] Prepare testbed for compilation of TensorFlow and run the baseline benchmark
    \item[Oct 12] First draft of the research plan, presentation, and peer review
    \item[Oct 15] Run the experiment for the selected subset of memory allocation algorithms
    \item[Oct 29] Finished running the experiment, begin drafting report and presentation
    \item[Nov 19] First version of report and presentation ready, including the structure and report headlines
    \item[Nov 30] First draft and Presentation with peer review of draft report and presentation
    \item[Dec 10] Opposition, improve the report based on the results from the opposition
    \item[Dec 17] Improved version of the report
    \item[Jan 15] Deliver final report 
\end{enumerate}

\noindent A graphical representation of the project plan can be found in Appendix \ref{sec:gantt}.

\bibliography{II2202-report}
%\todo{If possible, please use the Zotero style: http://people.kth.se/~maguire/ExampleStyle-with-access.csl see also https://www.zotero.org/styles}
%%\bibliographystyle{IEEEtran}
\bibliographystyle{myIEEEtran}

\appendix
\section{Project Gantt Chart}
\label{sec:gantt}

\begin{ganttchart}[vgrid,today=7,
            x unit=0.70cm,
            y unit title=0.7cm,
            y unit chart=0.725cm,
            bar label font=\footnotesize,
            milestone label font=\footnotesize,
            group label font=\footnotesize,
            title label font=\footnotesize
]{1}{21}
    \gantttitle{2018}{18}
    \gantttitle{2019}{3} \\
    \gantttitle{Aug}{1}
    \gantttitle{Sep}{4}
    \gantttitle{Oct}{4}
    \gantttitle{Nov}{5}
    \gantttitle{Dec}{4}
    \gantttitle{Jan}{3} \\
    \gantttitle{W1}{1}
    \gantttitle{W2}{1}
    \gantttitle{W3}{1}
    \gantttitle{W4}{1}
    \gantttitle{W5}{1}
    \gantttitle{W6}{1}
    \gantttitle{W7}{1}
    \gantttitle{W8}{1}
    \gantttitle{W9}{1}
    \gantttitle{W10}{1}
    \gantttitle{W11}{1}
    \gantttitle{W12}{1}
    \gantttitle{W13}{1}
    \gantttitle{W14}{1}
    \gantttitle{W15}{1}
    \gantttitle{W16}{1}
    \gantttitle{W17}{1}
     \gantttitle{Christmas}{2}
    \gantttitle{W18}{1}
    \gantttitle{W19}{1}
    
    
    \ganttgroup{Experiment}{2}{9} \ganttnewline
    \ganttgroup{Report}{9}{15} \ganttnewline
    \ganttgroup{Opposition}{13}{17} \ganttnewline
    
    \ganttbar{Literature study}{1}{8} \ganttnewline
    \ganttmilestone{Project plan 1}{2} \ganttnewline
    \ganttbar{Tools setup}{3}{9} \ganttnewline
    \ganttmilestone{Project plan 2}{7} \ganttnewline
    \ganttbar{Obtain data}{9}{11} \ganttnewline
    \ganttbar{Write report}{9}{19} \ganttnewline
    
    \ganttmilestone{First report}{10} \ganttnewline
    \ganttmilestone{Second report}{15} \ganttnewline
    \ganttmilestone{Third report}{17} \ganttnewline
    \ganttmilestone{Final report \& presentation}{20} \ganttnewline
    \ganttbar{Write opposition}{13}{15} \ganttnewline
    \ganttmilestone{Opposition}{15} \ganttnewline
    \ganttlink{elem8}{elem9} % Write report -> First report
    \ganttlink{elem4}{elem5} % Tools setup -> Obtain data
    
    % Link buldge / Link mid tries not to overlap arrows with each other. It's like spacing for arrows.
    %\ganttlink[link bulge=0.7, link mid=0.3]{elem13}{elem14} % Write opposition -> Opposition
    \ganttlink{elem13}{elem14} % Write opposition -> Opposition
    \ganttlink{elem8}{elem10} % Write report -> Second report
    \ganttlink{elem8}{elem11} % Write report -> Third report
    \ganttlink{elem8}{elem12} % Write report -> Final report
    \ganttlink{elem13}{elem12} % Write opposition -> Final report
    
    
    
\end{ganttchart}

\end{document}
